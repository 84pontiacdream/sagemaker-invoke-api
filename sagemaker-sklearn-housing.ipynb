{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Rest API for Sagemaker Endpoint using Lambda & API Gateway"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook:\n",
    "\n",
    "* Deploy a machine learning model using Random Forest Regressor to predict house prices using the [California Housing](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_california_housing.html) dataset, present in Scikit-Learn. \n",
    "\n",
    "This notebook is run in Sagemaker Studio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy the Sagemaker Endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (i) Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "import datetime\n",
    "import time\n",
    "import tarfile\n",
    "\n",
    "# initialise Boto3 SDK\n",
    "sm_boto3 = boto3.client(\"sagemaker\")\n",
    "sess = sagemaker.Session()\n",
    "region = sess.boto_session.region_name\n",
    "\n",
    "bucket = \"bucket_name\" # Add the name of the S3 bucket here\n",
    "print(\"Using bucket \" + bucket)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (ii) Train and test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = fetch_california_housing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, test_size=0.2, random_state=13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (iii) Create CSV Files for Train and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX = pd.DataFrame(X_train, columns=data.feature_names)\n",
    "trainX[\"target\"] = y_train\n",
    "\n",
    "testX = pd.DataFrame(X_test, columns=data.feature_names)\n",
    "testX[\"target\"] = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX.to_csv(\"california_housing_train.csv\")\n",
    "testX.to_csv(\"california_housing_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (iv) Upload test and train data into S3 Bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sk_prefix = \"sagemaker/california_housing/sklearncontainer\"\n",
    "trainpath = sess.upload_data(path=\"california_housing_train.csv\", \n",
    "                             bucket=bucket, \n",
    "                             key_prefix=sk_prefix)\n",
    "testpath = sess.upload_data(path=\"california_housing_test.csv\", \n",
    "                            bucket=bucket, \n",
    "                            key_prefix=sk_prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (v) Create training script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile script.py\n",
    "\n",
    "import argparse\n",
    "import joblib\n",
    "import os\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import boto3\n",
    "import pathlib\n",
    "from io import StringIO \n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "\n",
    "# inference functions ---------------\n",
    "\n",
    "def input_fn(request_body, request_content_type):\n",
    "    print(request_body)\n",
    "    print(request_content_type)\n",
    "    if request_content_type == \"text/csv\":\n",
    "        request_body = request_body.strip()\n",
    "        try:\n",
    "            df = pd.read_csv(StringIO(request_body), header=None)\n",
    "            return df\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    else:\n",
    "        return \"\"\"Please use Content-Type = 'text/csv' and, send the request!!\"\"\" \n",
    " \n",
    "    \n",
    "def model_fn(model_dir):\n",
    "    clf = joblib.load(os.path.join(model_dir, \"model.joblib\"))\n",
    "    return clf\n",
    "\n",
    "def predict_fn(input_data, model):\n",
    "    if type(input_data) != str:\n",
    "        prediction = model.predict(input_data)\n",
    "        print(prediction)\n",
    "        return prediction\n",
    "    else:\n",
    "        return input_data\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"[INFO] Extracting arguments\")\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    # hyperparameters sent by the client are passed as command-line arguments to the script.\n",
    "    parser.add_argument(\"--n-estimators\", type=int, default=10)\n",
    "    parser.add_argument(\"--min-samples-leaf\", type=int, default=3)\n",
    "\n",
    "    # Data, model, and output directories\n",
    "    parser.add_argument(\"--model-dir\", type=str, default=os.environ.get(\"SM_MODEL_DIR\"))\n",
    "    parser.add_argument(\"--train\", type=str, default=os.environ.get(\"SM_CHANNEL_TRAIN\"))\n",
    "    parser.add_argument(\"--test\", type=str, default=os.environ.get(\"SM_CHANNEL_TEST\"))\n",
    "    parser.add_argument(\"--train-file\", type=str, default=\"california_housing_train.csv\")\n",
    "    parser.add_argument(\"--test-file\", type=str, default=\"california_housing_test.csv\")\n",
    "    parser.add_argument(\n",
    "        \"--features\", type=str\n",
    "    )  # in this script we ask user to explicitly name features\n",
    "    parser.add_argument(\n",
    "        \"--target\", type=str\n",
    "    )  # in this script we ask user to explicitly name the target\n",
    "\n",
    "    args, _ = parser.parse_known_args()\n",
    "\n",
    "    print(\"SKLearn Version: \", sklearn.__version__)\n",
    "    print(\"Joblib Version: \", joblib.__version__)\n",
    "\n",
    "    print(\"[INFO] Reading data\")\n",
    "    print()\n",
    "    train_df = pd.read_csv(os.path.join(args.train, args.train_file))\n",
    "    test_df = pd.read_csv(os.path.join(args.test, args.test_file))\n",
    "\n",
    "    print(\"Building training and testing datasets\")\n",
    "    print()\n",
    "    X_train = train_df[args.features.split()]\n",
    "    X_test = test_df[args.features.split()]\n",
    "    y_train = train_df[args.target]\n",
    "    y_test = test_df[args.target]\n",
    "\n",
    "    print(\"Training Random Forest model\")\n",
    "    model = RandomForestRegressor(\n",
    "        n_estimators=args.n_estimators, min_samples_leaf=args.min_samples_leaf, n_jobs=-1\n",
    "    )\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    path = os.path.join(args.model_dir, \"model.joblib\")\n",
    "    joblib.dump(model, path)\n",
    "    print(\"Model persisted at \" + path)\n",
    "    print()\n",
    "\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    test_mse = mean_squared_error(y_test,y_pred_test)\n",
    "    test_r2 = r2_score(y_test,y_pred_test)\n",
    "\n",
    "    print()\n",
    "    print(\"---- METRICS RESULTS FOR TESTING DATA ----\")\n",
    "    print()\n",
    "    print(\"Total Rows are: \", X_test.shape[0])\n",
    "    print('[TESTING] Model Mean Squared Error: ', test_mse)\n",
    "    print('[TESTING] Testing Model R^2 Score: ', test_r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (v) Run script inside this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python script.py --n-estimators 100 \\\n",
    "                   --min-samples-leaf 2 \\\n",
    "                   --model-dir ./ \\\n",
    "                   --train ./ \\\n",
    "                   --test ./ \\\n",
    "                   --features 'MedInc HouseAge AveRooms AveBedrms Population AveOccup Latitude Longitude' \\\n",
    "                   --target target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(vi) Train inside Sagemaker container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "\n",
    "FRAMEWORK_VERSION = \"0.23-1\"\n",
    "\n",
    "sklearn_estimator = SKLearn(\n",
    "    entry_point=\"script.py\",\n",
    "    role=get_execution_role(),\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    "    framework_version=FRAMEWORK_VERSION,\n",
    "    base_job_name=\"RF-custom-sklearn\",\n",
    "    hyperparameters={\n",
    "        \"n-estimators\": 100,\n",
    "        \"min-samples-leaf\": 3,\n",
    "        \"features\": \"MedInc HouseAge AveRooms AveBedrms Population AveOccup Latitude Longitude\",\n",
    "        \"target\": \"target\",\n",
    "    },\n",
    "    use_spot_instances = True,\n",
    "    max_wait = 7200,\n",
    "    max_run = 3600\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn_estimator.fit({\"train\": trainpath, \"test\": testpath}, wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (vii) Store Model Artifacts into the S3 Bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn_estimator.latest_training_job.wait(logs=\"None\")\n",
    "artifact = sm_boto3.describe_training_job(\n",
    "    TrainingJobName=sklearn_estimator.latest_training_job.name\n",
    ")[\"ModelArtifacts\"][\"S3ModelArtifacts\"]\n",
    "\n",
    "print(\"Model artifact persisted at \" + artifact)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (viii) Deploy SageMaker Endpoint (API) for trained model and test it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.sklearn.model import SKLearnModel\n",
    "from time import gmtime, strftime\n",
    "\n",
    "model_name = \"Custom-sklearn-model-\" + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "model = SKLearnModel(\n",
    "    name =  model_name,\n",
    "    model_data=artifact,\n",
    "    role=get_execution_role(),\n",
    "    entry_point=\"script.py\",\n",
    "    framework_version=FRAMEWORK_VERSION,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_name = \"Custom-sklearn-model-\" + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "print(\"EndpointName={}\".format(endpoint_name))\n",
    "\n",
    "predictor = model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.m4.xlarge\",\n",
    "    endpoint_name=endpoint_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this line to delete the endpoint\n",
    "# sm_boto3.delete_endpoint(EndpointName=endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import requests\n",
    "\n",
    "url = \"<api_url>\"\n",
    "\n",
    "payload = \"4.7, 27, 6.5, 1, 1000, 3, 37.54, -121.72\"\n",
    "\n",
    "headers = {\n",
    "    'Content-Type': 'text/csv'\n",
    "}\n",
    "\n",
    "response = requests.request(\"POST\", url, headers=headers, data=payload)\n",
    "\n",
    "print(response.text)    \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
